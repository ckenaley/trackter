% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kin.R
\name{kin.simple}
\alias{kin.simple}
\title{Simplified midline tracking over image sequences}
\usage{
kin.simple(image.dir = NULL, frames = NULL, thr = 0.7,
  size.min = 0.05, ant.per = 0.2, tips = 0.02, smoothing = "loess",
  smooth = 0.2, smooth.points = 200, save = TRUE, plot.pml = TRUE,
  image.type = "orig", flip = TRUE, show.prog = FALSE)
}
\arguments{
\item{image.dir}{character, directory containing images to analyze.}

\item{frames}{numeric, vector indicating which images to process.}

\item{thr}{numeric or character ('otsu') threshold to determine binary image. See Details.}

\item{size.min}{numeric, indicating the minimum size of ROIs as a proportion of the pixel field to be considered in analysis. May be useful if smaller unimportant ROIs appear in the frame. Default is 0.05.}

\item{ant.per}{numeric; left-most proportion of ROI that establishes the horizontal reference for the midline displacement.}

\item{tips, }{numeric, the proportion the the midline data to use in calculation of the head and tail position.}

\item{smoothing}{character, the midline smoothing method, either 'loess' or 'spline'.}

\item{smooth}{numeric; if \code{smoothing} is set to 'loess', passed to 'span' parameter of \code{\link{loess}}. If \code{smoothing} is set to 'spline', passed to 'spar' parameter of \code{\link{smooth.spline}}}

\item{smooth.points}{numeric, number of equally spaced points along the ROI midline on which the smoothed midline is computed.}

\item{save}{logical, value indicating if images should be outputted with midline and predicted midline based on the \code{lm()} predictions from \code{ant.per}overlaying original or binary images.}

\item{plot.pml}{logical, value indicating if outputted images should include the predicted midline (in blue) and the points according to \code{ant.per} used to construct the predicted midline (in green).}

\item{image.type}{character; the type of image to be outputted, either 'orig' or 'bin' representing the original or binary images, respectively. Ignored if 'save=FALSE'.}

\item{flip}{logical, indicating if binary image should be flipped.}

\item{show.prog}{logical, indicating if outputted image should be displayed during analysis.}
}
\value{
A list with the following components:

\code{kin.dat} a data table consisting of frame-by-frame position parameters for the ROI determined by LDA analysis.
\itemize{
\item the frame number
\item 'x' and 'y': the position of the tail (rightmost or posteriormost)
\item 'head.x' and 'head.y': the x and y position of the head (leftmost or anteriormost)
\item 'amp': the amplitude (\code{amp}) of the tail relative to the theoretical midline determined by the \code{lm()} predictions from \code{ant.per}
\item 'roi': a character indicating the ROI ranked by size ('a' being the largest)
\item 'head.pval': p values of the \code{lm()} fit that describes the position of the head as determined by \code{ant.per} (green points in the outputted images/video)}

\code{midline} A data table containing, for each frame described by \code{frames}, the following: \itemize{
\item 'x' and 'y.m': x and y positions of the midline of the ROI
#' \item 'y.min' and 'y.max': min and max y positions ROI's countour used in y.m calculation
\item 'mid.pred': the predicted linear midline based on the points/pixels defined by \code{ant.per} (green points in the outputted images/video if 'plot.pml=TRUE')
\item 'y.pred': midline points fit to a smooth spline or loess model with spar or span equal to \code{smooth} (red curve in the outputted images/video)
\item 'wave.y': midline points 'y.pred' relative to 'mid.pred'
\item 'roi': a character indicating ROI size ('a' being the largest)
}

\code{cont} A data table containing x and y positions of the contours used to calculate the data in 'kin.dat'. Contains the following: 
\itemize{
\item 'frame': the frame
\item 'x' and 'y': the x and y positions of the countours
}

\code{all.classes} A data table containing the following for all ROIs detected:  
\itemize{
\item 'frame': the frame
\item 'roi': the name of each ROI found in a frame.
\item 'size': the size of each ROI
}

\code{dim} the x and y dimensions of the images analyzed
}
\description{
Automatically retrieves the midline of a detected ROIbased on size. Assumes the ROI of interest is the largest detected and not interesecting the edges of the image frame, conditions often met in kinematic studies. For each ROI of interest, finds the y-value midpoint along the x-value array of the ROI and fits a midline according to a chosen smoothing method (loess or spline). Also outputs the midline amplitude relative to a reference line determined by an anterior section of the ROI and outputs contours ROIs in each frame for subsequent analysis. Supported image formats are jpeg, png, and tiff.
}
\details{
The algorithm assumes a left-right orientation, i.e., the head of the ROI is positioned left, the tail right. ffmpeg operations or even imageJ can rotate images not in this orientation. The \code{ant.per} value therefor establishes the reference line (theoretical straight midline) based on that portion of the head.  If 'save=TRUE', images are saved as binary or the original with a body mideline overlay and, if chosen, with the theoretical midline (based on \code{ant.per}). 

Thresholding operations can be performed with an arbitrary (user defined) numeric value or with Otsu's method ('thr="otsu"'). The latter choses a threshold value by minimizing the combined intra-class variance. See \code{\link{otsu}}.
}
\examples{
# produce a classic midline waveform plot of swimming fish 
# searching a image field with a two fish-like ROIs
\dontrun{
require(wesanderson)

#download example avi video
f <- "https://github.com/ckenaley/exampledata/blob/master/trout1_63_test.avi?raw=true"
download.file(f,"trout1_63_test.avi")

#extract images and reduce them to 600 px wide with a filter
filt.red <- " -vf scale=600:-1 " #filter
vid.to.images2(vid.path="trout1_63_test.avi",filt = filt.red) #extract

#number of frames
fr <-1:50
#extract midline and other data
kin <- kin.simple(image.dir = "images",frames=fr,thr=0.6,ant.per = 0.2,show.prog=T)
ml <- kin$midline
#normalize x (y is normalized to midline by \\code{kin.simple})
ml <- ddply(ml,.(frame),transform,x2=x-x[1])

#compute instantaneous amplitude of tail (last/rightmost points) and wave crest x position  by frame
ml2 <- ddply(ml,.(frame),summarize,amp.i=abs(last(wave.y)))

ml <- merge(ml,ml2,by="frame") #merge these

pal <- wes_palette("Zissou1", 100, type = "continuous") #"Zissou" color palette
p <- ggplot(dat=ml,aes(x=x2,y=wave.y))+theme_classic(15)+scale_color_gradientn(colours = pal)
p <- p+geom_line(aes(group=frame,color=amp.i),stat="smooth",
method = "loess", size = 1.5,alpha = 0.5)
print(p)

#make a video of extracted midlines over original images
images.to.video2(image.dir = "processed_images",vid.name = "trout_test")

#delete 'images' and 'processed_images' folders and avi file
unlink("processed_images",recursive = T)
unlink("images",recursive = T)
unlink("trout1_63_test.avi",recursive = T)
}

}
\seealso{
\code{\link{kin.search}}
}
