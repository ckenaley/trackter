% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kin2.R
\name{kin.img2}
\alias{kin.img2}
\title{Midline tracking over image seqences}
\usage{
kin.img2(image.dir = NULL, sequenced = TRUE, frames = NULL,
  thr = 0.7, plot.pml = TRUE, show.prog = FALSE, ant.per = 0.1,
  smoothing = "loess", smooth = 0.2, smooth.points = 200,
  image.type = "orig", save = TRUE, flip = TRUE, rem.file = FALSE,
  frame.rate = 10, size.min = 0.05, n.blob = NULL,
  search.for = "largest", burn = 10)
}
\arguments{
\item{image.dir}{Directory containing images to analyze.}

\item{sequenced}{logical, do the names of the image sequence end in a number sequence. If set to 'TRUE', output video will be named the file base name of the first image minus the image number ('gsub("(.+)\\_\\d*$", "\\1", image[1])')}

\item{frames}{numeric, vector indicating which images to process.}

\item{thr}{numeric, threshold to determine binary image. May require some tweaking through iteration.}

\item{show.prog}{logical value indicating if outputted image should be displayed during analysis.}

\item{smoothing}{character, the midline smoothing method, either 'loess' or "spline".}

\item{smooth}{numeric; if \code{smoothing} is set to 'loess', smoothing parameter value for plotted midline.}

\item{smooth.points}{numeric, number of equally spaced points along the ROI midline on which the smoothed midline is computed.}

\item{image.type}{character; the type of image to be outputted, either 'orig' or 'bin' representing the original or binary images, respectively. Ignored if 'save=FALSE'.}

\item{flip}{logical, indicating if binary should be flipped.}

\item{rem.file}{logical value indicating if the outputted images, both from the original video and images with midline overlay, should be deleted.}

\item{size.min}{numeric, indicating the minimum size of ROIs as a proportion of the pixel field to be considered in analysis. May be useful if smaller unimportant ROIs appear in the frame. Default is 0.02.}

\item{n.blob}{numeric, indicating which nth largest ROI is the ROI to be analyzed. May require tweaking through iteration. Perhaps best to let the function choose by using "search.for".
#' @param save logical, value indicating if images should be outputted with midline and predicted midline based on the \code{ant.per} \code{lm()} overlaying original or binary images. Automatically set to 'TRUE' if 'make.video=TRUE'.}

\item{search.for}{character; the search parameter: "offset" the ROI closest to the midpoint of the field or "largest" the largest roi (equivalent to n.blob=1). Will produce a warning if the ROI indicated by either of these settings is one that has no positive pixels along 90\% of its midline (see details).}

\item{burn}{numeric, how many frames (a burn-in) should be used to determine the ROI. If all ROIs in the the burn-in frames are the same, the algorithm will choose that ROI in all subsequent frames. This should increase the speed of midline detection in post burn-in frames.}

\item{plot.ml}{logical, value indicating if outputted images should include an overlay of the theoretical amidline based on \code{ant.per}.}
}
\value{
A list with the following components:

\code{kin.dat} a data frame consisting of frame-by-frame position parameters for the ROI indicated by \code{n.blob}:
\itemize{
\item the frame number

\item 'head.x' and 'head.y': the x and y position of the head (leftmost or anteriormost)
\item 'x' and 'y': the position of the tail (rightmost or posteriormost)
\item 'amp': the amplitude (\code{amp}) of the tail
\item 'cent.x' and 'cent.y': centroid coordinate of ROI
\item 'roi': a character indicating ROI size ('a' being the largest)
\item 'head.pval': p values of the \code{lm()} fit that describes the position of the head as determined by \code{ant.per} (green points in the outputted images/video)}

\code{midline} A data frame containing, for each frame described by \code{frames}, the following: \itemize{
\item 'x' and 'y.m': x and y positions of the midline of the ROI
\item 'mid.pred': the predicted linear midline based on the points/pixels defined by \code{head.per} (green points in the outputted images/video)
\item 'y.pred': midline points fit to a smooth spline or loess model with spar or span equal to \code{smooth} (red curve in the outputted images/video)
\item 'wave.y': midline points 'y.pred' normalized to 'mid.pred'
\item 'roi': a character indicating ROI size (a being the largest)
\item 'cent.x': x centroid of ROI
\item 'cent.y': y centroid of ROI
\item 'offset.x': ROI distance from horizontal center
\item 'offset.y': ROI distance from vertical center
\item 'offset.total': sum of ROI offset.x and offset.y
\item 'ar': aspect ration of the ROI
\item 'size': size of ROI in pixels
}
 \code{head.lms}  'lm' objects, one for each frame described by \code{frames} of the linear model fit to the \code{ant.per} section of the ROI
}
\description{
Automatically retrieves the midline of a detected ROI in each image of a sequence; finds the y-value midpoint along the x-value array of the ROI and fits a midline according to a chosen smoothing method (loess or spline). Also outputs the midline amplitude relative to a reference line determined by an anterior section of the ROI. Supported image formats are jpeg, png, and tiff.
}
\details{
The algorithm assumes a left-right orientation, i.e., the head of the ROI is positioned left, the tail right. The \code{ant.per} value therefor establishes the reference line (theoretical straight midline) based on that portion of the head.  By default, images are outputted to the \code{image.dir} subdirectory in the working directory. Chooses ROIs based on relative ROI size or position.

\code{image.type} Can be set as "orig" or "bin". "orig" plots midline and reference lines over the original video frames, "bin" over binary images.
\code{n.blob} May be useful if there are other highly contrasted ROIs in the frame and the user expects and knows their relative size
\code{search.for} The algorithm attempts to resolve an ROI that has positive (i.e., dark) pixels along more than 90% of the ROI's midline. This should be useful if the ROI of interest is surrounded by irregular dark object (e.g., walls).

\code{make.video} If "TRUE" a video of the same names as \code{video.name}, if given, is created by \code{images.to.video2} and outputted in the working directory. If \code{video.name} is "NULL", a base name minus the image sequence number will be determined and "_kin" appended to the file name.

\code{rem.file} If "TRUE" and \code{make.video} is also "TRUE", a video of processed images is still produced.
}
\examples{
#produce a classic midline waveform plot of swimming fish
\dontrun{
require(wesanderson)
require(ggplot2)
require(data.table)
require(dplyr)
require(EBImage)

#download example images and place in 'example' subdirectory
f <- "https://github.com/ckenaley/exampledata/blob/master/example.zip?raw=true"
download.file(f,"temp.zip")
unzip("temp.zip")
unlink("temp.zip")

kin <- kin.img2(image.dir ="example",search.for = "largest",smoothing = "spline",frames=1:10,show.prog = T,thr = 0.6)
ml <- kin$midline
#normalize x (y is normalized to midline by "kin.img/kin.vid")
ml <- ddply(ml,.(frame),transform,x2=x-x[1])

#compute instantaneous amplitude of tail (last/rightmost point) and wave crest x position  by frame
ml2 <- ddply(ml,.(frame),summarize,amp.i=abs(last(wave.y)))

ml <- merge(ml,ml2,by="frame") #merge these

pal <- wes_palette("Zissou1", 100, type = "continuous") #"Zissou" color palette
p <- ggplot(dat=ml,aes(x=x2,y=wave.y))+theme_classic(15)+scale_color_gradientn(colours = pal)
p <- p+geom_line(aes(group=frame,color=amp.i),stat="smooth",method = "loess", size = 1.5,alpha = 0.5)
print(p)

### Make a video of processed frames

trackter::images.to.video2(image.dir = "processed_images", vid.name = "trout_test", qual=50,frame.rate =10,silent=T)
}

}
\seealso{
\code{\link{kin.LDA},\link{kin.simple}}
}
