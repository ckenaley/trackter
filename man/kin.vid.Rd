% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kin.R, R/kin2.R
\name{kin.vid}
\alias{kin.vid}
\alias{kin.vid}
\title{Retrives the midline of an ROI in each frame of a video.}
\usage{
kin.vid(vid.path = NULL, frames = NULL, thr = 0.7, plot.midline = TRUE,
  show.prog = FALSE, ant.per = 0.15, smooth = 0.2, image.type = "orig",
  flip = T, n.blob = NULL, rem.file = TRUE, make.video = T, qual = 50,
  frame.rate = 10)

kin.vid(vid.path = NULL, frames = NULL, thr = 0.7, plot.midline = TRUE,
  show.prog = FALSE, ant.per = 0.15, smooth = 0.2, image.type = "orig",
  flip = T, n.blob = NULL, rem.file = TRUE, make.video = T, qual = 50,
  frame.rate = 10)
}
\arguments{
\item{vid.path}{Character; path of video to be analyze.}

\item{frames}{numeric vectors indicating which video frames to process}

\item{thr}{numeric, threshhold to determine binary image. May require some tweeking through iteration}

\item{plot.midline}{logical value indicating if outputted images should inclued plotted midline and reference line.}

\item{show.prog}{logical value indicating if outputted image should be display during analysis.}

\item{ant.per}{numeric; left-most percentage of ROI that establishes the vertical reference for the midline displacement.}

\item{smooth}{numeric; smoothing parameter value for plotted midline}

\item{image.type}{character; the type of image to be outputted}

\item{flip}{logical, indicating if binary should be flipped}

\item{n.blob}{numeric, indicating which nth largest ROI is the ROI to be analyzed. May require tweeking through interation
#' @param make.video logical value indicating if a video should be saved of midline position overlaying origina frames}

\item{rem.file}{logical value indicating if the outputted images, both from the original video and images with midline overlay, should be deleted. Default is "TRUE".}

\item{qual}{numeric; quality of the outputted video from 1-100\%. Defaults to 50\%.}

\item{frame.rate}{numeric; outputted video frame rate in fps.}

\item{vid.path}{Character; path of video to be analyze.}

\item{frames}{numeric vectors indicating which video frames to process}

\item{thr}{numeric, threshhold to determine binary image. May require some tweeking through iteration}

\item{plot.midline}{logical value indicating if outputted images should inclued plotted midline and reference line.}

\item{show.prog}{logical value indicating if outputted image should be display during analysis.}

\item{smooth}{numeric; smoothing parameter value for plotted midline}

\item{image.type}{character; the type of image to be outputted}

\item{n.blob}{numeric, indicating which nth largest ROI is the ROI to be analyzed. May require tweeking through interation
#' @param make.video logical value indicating if a video should be saved of midline position overlaying origina frames}

\item{qual}{numeric; quality of the outputted video from 1-100\%. Defaults to 50\%.}

\item{ant.per}{numeric; left-most percentage of ROI that establishes the vertical reference for the midline displacement.}

\item{frame.rate}{numeric; outputted video frame rate in fps.}

\item{rem.file}{logical value indicating if the outputted images, both from the original video and images with midline overlay, should be deleted. Default is "TRUE".}
}
\value{
A list with the following components:

\code{kin.dat} a data frame consisting of position paramters for the ROI indicated by \code{n.blob}:\itemize{
\item the frame number
\item "head.x" and "head.y": the x and y position of the head (leftmost or anteriormost)
\item "x" and ""y": the position of the tail (rightmost or posteriormost)
\item "amp": the amplitude (\code{amp}) of the tail
\item "head.pval": p values of the \code{lm()} fit that describes the position of the head as determined by \code{ant.per} (green points in the outputted images/video)}

\code{midline} A data frame containing, for each frame described by \code{frames}, the following: \itemize{
\item "x" and "y.m": x and y positions of the midline of the ROI
\item "mid.pred": the predicted linear midline based on the points/pixels defined by \code{head.per} (green points in the outputted images/video)
\item "y.pred": midline points fit to a loess smoothing model with span equal to \code{smooth} (red curve in the outputted images/video)
\item "wave.y": midline points "y.pred" normalized to "mid.pred"}

 \code{head.lms}  "lm" objects, one for each frame desrbied by \code{frames} of the linear model fit to the \code{ant.per} section of the ROI

A list with the following components:

\code{kin.dat} a data frame consisting of position paramters for the ROI indicated by \code{n.blob}:\itemize{
\item the frame number
\item "head.x" and "head.y": the x and y position of the head (leftmost or anteriormost)
\item "x" and ""y": the position of the tail (rightmost or posteriormost)
\item "amp": the amplitude (\code{amp}) of the tail
\item "head.pval": p values of the \code{lm()} fit that describes the position of the head as determined by \code{ant.per} (green points in the outputted images/video)}

\code{midline} A data frame containing, for each frame described by \code{frames}, the following: \itemize{
\item "x" and "y.m": x and y positions of the midline of the ROI
\item "mid.pred": the predicted linear midline based on the points/pixels defined by \code{head.per} (green points in the outputted images/video)
\item "y.pred": midline points fit to a loess smoothing model with span equal to \code{smooth} (red curve in the outputted images/video)
\item "wave.y": midline points "y.pred" normalized to "mid.pred"}

 \code{head.lms}  "lm" objects, one for each frame desrbied by \code{frames} of the linear model fit to the \code{ant.per} section of the ROI
}
\description{
Retrives the midline of an ROI in each frame of a video.

Retrives the midline of a detected ROI in each frame of a video.
}
\details{
By default, images are outputted to an "images" subdirectory in the working directory.

\code{image.type} Can be set as "orig" or "bin". "orig" plots midline and reference lines over the orginal video frames, "bin" over binary images.
\code{n.blob} May be useful if there are other highly contrasted ROIs in the frame.

\code{make.video} If "TRUE" a video of the same names as \code{video.name} is outputted in the working directory.

\code{rem.file} If "TRUE", \code{make.video} is also "TRUE" a video of processed images is still produced.

Assumes images are appended with a numeric sequence.

By default, images are outputted to an "images" subdirectory in the working directory.

\code{image.type} Can be set as "orig" or "bin". "orig" plots midline and reference lines over the orginal video frames, "bin" over binary images.
\code{n.blob} May be useful if there are other highly contrasted ROIs in the frame.

\code{make.video} If "TRUE" a video of the same names as \code{video.name} is outputted in the working directory.

\code{rem.file} If "TRUE", \code{make.video} is also "TRUE" a video of processed images is still produced.

Assumes images are appended with a numeric sequence. Chooses ROIs that are big (>5\% of the pixel field) and identifies the one with the largest variance to the trailing edge amplitude (i.e., assumes that ROI is the one moving)
}
\examples{
#produce a classic midline waveform plot of swimming fish

require(wesanderson)
require(ggplot2)
require(plyr)

#download an example video (7.5 MB) and place in working directory
f <- "https://github.com/ckenaley/exampledata/blob/master/trout1_63_test.avi?raw=true"
download.file(f, file.path(getwd(), "trout1_63_test.avi"), method = "libcurl")
kin <- kin.vid(vid.path ="trout1_63_test.avi",thr=0.7,frames=1:20,frame.rate=10)

ml <- kin$midline
#normalize x (y is normalized to midline by "kin.img/kin.vid")
ml <- ddply(ml,.(frame),transform,x2=x-x[1])

#compute instantaneous amplitude of tail (last/rightmost point) and wave crest x position  by frame
ml2 <- ddply(ml,.(frame),summarize,amp.i=last(wave.y))

ml <- merge(ml,ml2,by="frame") #merge these

pal <- wes_palette("Zissou1", 100, type = "continuous") #"Zissou" color palette
p <- ggplot(dat=ml,aes(x=x2,y=wave.y))+theme_classic(15)+scale_color_gradientn(colours = pal)
p+geom_line(aes(group=frame,color=amp.i),stat="smooth",method = "loess", size = 1.5,alpha = 0.5)

#produce a classic midline waveform plot of swimming fish

require(wesanderson)
require(ggplot2)
require(plyr)

#download an example video (7.5 MB) and place in working directory
f <- "https://github.com/ckenaley/exampledata/blob/master/trout1_63_test.avi?raw=true"
download.file(f, file.path(getwd(), "trout1_63_test.avi"), method = "libcurl")
kin <- kin.vid(vid.path ="trout1_63_test.avi",thr=0.7,frames=1:20,frame.rate=10)

ml <- kin$midline
#normalize x (y is normalized to midline by "kin.img/kin.vid")
ml <- ddply(ml,.(frame),transform,x2=x-x[1])

#compute instantaneous amplitude of tail (last/rightmost point) and wave crest x position  by frame
ml2 <- ddply(ml,.(frame),summarize,amp.i=last(wave.y))

ml <- merge(ml,ml2,by="frame") #merge these

pal <- wes_palette("Zissou1", 100, type = "continuous") #"Zissou" color palette
p <- ggplot(dat=ml,aes(x=x2,y=wave.y))+theme_classic(15)+scale_color_gradientn(colours = pal)
p+geom_line(aes(group=frame,color=amp.i),stat="smooth",method = "loess", size = 1.5,alpha = 0.5)

}
\seealso{
\code{\link{kin.img}}

\code{\link{kin.img}}
}
